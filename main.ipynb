{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Project\n",
    "## Istanbul Technical University\n",
    "### Computer Engineering Department\n",
    "### BLG 527E - Deep Learning\n",
    "### Spring 2023\n",
    "\n",
    "<b>Student Name: Muhammed Rüşen Birben</b><br>\n",
    "<b>Student ID: 150220755</b><br>\n",
    "<b>Student Email: birben20@itu.edu.tr</b><br>\n",
    "\n",
    "<b>Student Name: Ahmed Burak Ercan</b><br>\n",
    "<b>Student ID: 150220749</b><br>\n",
    "<b>Student Email: ercana20@itu.edu.tr</b><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from os import makedirs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from utils import get_model, model_predict, get_label_output\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data.\n",
    "df = pd.read_csv('datasetV2.csv')\n",
    "df.head()\n",
    "df = df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[:100].Text\n",
    "y = df[:100].IsAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model_name, X):\n",
    "    # load model\n",
    "    model, tokenizer = get_model(model_name)\n",
    "\n",
    "    # sentences\n",
    "    text = X.values.tolist()\n",
    "\n",
    "    # predict\n",
    "    predictions = model_predict(model, tokenizer, text)\n",
    "\n",
    "    return predictions, model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(y_predictons, y_true):\n",
    "    #Evaluate the model by computing precision, recall and F1-score.\n",
    "    pred_labels = get_label_output(y_predictons)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, pred_labels)\n",
    "    recall = recall_score(y_true, pred_labels, average='macro')\n",
    "    precision = precision_score(y_true, pred_labels, average='macro')\n",
    "    f1 = f1_score(y_true, pred_labels, average='macro')\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_true, pred_labels)\n",
    "    \n",
    "    print('Accuracy: {:.2f}%'.format(accuracy*100))\n",
    "    print('Recall: {:.2f}%'.format(recall*100))\n",
    "    print('Precision: {:.2f}%'.format(precision*100))\n",
    "    print('F1-score: {:.2f}%'.format(f1*100))\n",
    "\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already exists, loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "predictions, model, tokenizer = predict(\"chatgpt-detector-lli-hc3\", X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.00%\n",
      "Recall: 54.68%\n",
      "Precision: 54.62%\n",
      "F1-score: 54.64%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[14, 20],\n",
       "       [21, 45]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(predictions, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the DataFrame into train and remaining datasets\n",
    "train_df, remaining_df = train_test_split(df, test_size=0.30, random_state=42)\n",
    "\n",
    "# Splitting the remaining dataset into validation and test datasets\n",
    "val_df, test_df = train_test_split(remaining_df, test_size=0.4, random_state=42)\n",
    "\n",
    "\n",
    "train_encodings = tokenizer(train_df['Text'].tolist(), padding=True, truncation=True, max_length=512)\n",
    "val_encodings = tokenizer(val_df['Text'].tolist(), padding=True, truncation=True, max_length=512)\n",
    "test_encodings = tokenizer(test_df['Text'].tolist(), padding=True, truncation=True, max_length=512)\n",
    "\n",
    "train_dataset = TextDataset(train_encodings, train_df['IsAI'].tolist())\n",
    "val_dataset = TextDataset(val_encodings, val_df['IsAI'].tolist())\n",
    "test_dataset = TextDataset(test_encodings, test_df['IsAI'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cafdc7e5ed6430d9b7e8c51338de39d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd732e13924340cd82b80532b3f4b396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3414738178253174, 'eval_runtime': 2.2329, 'eval_samples_per_second': 8.061, 'eval_steps_per_second': 1.344, 'epoch': 1.0}\n",
      "{'loss': 1.5254, 'learning_rate': 1.0000000000000002e-06, 'epoch': 1.11}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913e3797c637440cbf4ab78a52903376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.273801326751709, 'eval_runtime': 2.2422, 'eval_samples_per_second': 8.028, 'eval_steps_per_second': 1.338, 'epoch': 2.0}\n",
      "{'loss': 1.0252, 'learning_rate': 2.0000000000000003e-06, 'epoch': 2.22}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b89716e364e4067ae14249442bef6b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1937499046325684, 'eval_runtime': 2.269, 'eval_samples_per_second': 7.933, 'eval_steps_per_second': 1.322, 'epoch': 3.0}\n",
      "{'train_runtime': 117.3427, 'train_samples_per_second': 1.79, 'train_steps_per_second': 0.23, 'train_loss': 1.1908508936564128, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=27, training_loss=1.1908508936564128, metrics={'train_runtime': 117.3427, 'train_samples_per_second': 1.79, 'train_steps_per_second': 0.23, 'train_loss': 1.1908508936564128, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",          # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=8,   # batch size per device during training\n",
    "    per_device_eval_batch_size=8,    # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\"      # evaluate each `logging_steps`\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset             # evaluation dataset\n",
    ")\n",
    "\n",
    "# Train and evaluate\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0bb23de9cc54e728547da6caccb012c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax\n",
    "predictons = F.softmax(torch.from_numpy(predictions.predictions), dim=1)\n",
    "predictons = predictons.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argmax label\n",
    "pred_labels = get_label_output(predictons)\n",
    "y = test_df['IsAI'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 41.67%\n",
      "Recall: 37.50%\n",
      "Precision: 38.57%\n",
      "F1-score: 37.78%\n"
     ]
    }
   ],
   "source": [
    "#eval_model(pred_labels, y) # y düzenle\n",
    "\n",
    "accuracy = accuracy_score(y, pred_labels)\n",
    "recall = recall_score(y, pred_labels, average='macro')\n",
    "precision = precision_score(y, pred_labels, average='macro')\n",
    "f1 = f1_score(y, pred_labels, average='macro')\n",
    "\n",
    "conf_matrix = confusion_matrix(y, pred_labels)\n",
    "\n",
    "print('Accuracy: {:.2f}%'.format(accuracy*100))\n",
    "print('Recall: {:.2f}%'.format(recall*100))\n",
    "print('Precision: {:.2f}%'.format(precision*100))\n",
    "print('F1-score: {:.2f}%'.format(f1*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
